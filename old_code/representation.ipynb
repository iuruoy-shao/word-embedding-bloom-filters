{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m frequencies\u001b[38;5;241m.\u001b[39mitems(): \u001b[38;5;66;03m# applies new lemmatizer\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     frequencies[k] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m:v\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m'\u001b[39m:v\u001b[38;5;241m.\u001b[39mvalues()}) \n\u001b[0;32m---> 14\u001b[0m     frequencies[k] \u001b[38;5;241m=\u001b[39m frequencies[k]\u001b[38;5;241m.\u001b[39mloc[\u001b[43mfrequencies\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynsets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     15\u001b[0m     frequencies[k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemmas\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m frequencies[k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(lemmatize)\n\u001b[1;32m     16\u001b[0m     frequencies[k] \u001b[38;5;241m=\u001b[39m frequencies[k]\u001b[38;5;241m.\u001b[39mgroupby(frequencies[k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemmas\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39maggregate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/pandas/core/series.py:4700\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[1;32m   4621\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4622\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   4623\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4624\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4626\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4627\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4698\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4699\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4700\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4702\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4703\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m frequencies\u001b[38;5;241m.\u001b[39mitems(): \u001b[38;5;66;03m# applies new lemmatizer\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     frequencies[k] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m:v\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m'\u001b[39m:v\u001b[38;5;241m.\u001b[39mvalues()}) \n\u001b[0;32m---> 14\u001b[0m     frequencies[k] \u001b[38;5;241m=\u001b[39m frequencies[k]\u001b[38;5;241m.\u001b[39mloc[frequencies[k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mbool\u001b[39m(\u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynsets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))]\n\u001b[1;32m     15\u001b[0m     frequencies[k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemmas\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m frequencies[k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(lemmatize)\n\u001b[1;32m     16\u001b[0m     frequencies[k] \u001b[38;5;241m=\u001b[39m frequencies[k]\u001b[38;5;241m.\u001b[39mgroupby(frequencies[k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemmas\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39maggregate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1758\u001b[0m, in \u001b[0;36mWordNetCorpusReader.synsets\u001b[0;34m(self, lemma, pos, lang, check_exceptions)\u001b[0m\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1756\u001b[0m         pos \u001b[38;5;241m=\u001b[39m POS_LIST\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m-> 1758\u001b[0m         \u001b[43mget_synset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1759\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pos\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m form \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_morphy(lemma, p, check_exceptions)\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m offset \u001b[38;5;129;01min\u001b[39;00m index[form]\u001b[38;5;241m.\u001b[39mget(p, [])\n\u001b[1;32m   1762\u001b[0m     ]\n\u001b[1;32m   1764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_lang_data(lang)\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1559\u001b[0m, in \u001b[0;36mWordNetCorpusReader.synset_from_pos_and_offset\u001b[0;34m(self, pos, offset)\u001b[0m\n\u001b[1;32m   1554\u001b[0m line_offset \u001b[38;5;241m=\u001b[39m data_file_line[:\u001b[38;5;241m8\u001b[39m]\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1556\u001b[0m     line_offset\u001b[38;5;241m.\u001b[39misalnum()\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m line_offset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(offset)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(offset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1558\u001b[0m ):\n\u001b[0;32m-> 1559\u001b[0m     synset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_synset_from_pos_and_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_file_line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1560\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m synset\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m==\u001b[39m offset\n\u001b[1;32m   1561\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_synset_offset_cache[pos][offset] \u001b[38;5;241m=\u001b[39m synset\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1675\u001b[0m, in \u001b[0;36mWordNetCorpusReader._synset_from_pos_and_line\u001b[0;34m(self, pos, data_file_line)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lemma \u001b[38;5;129;01min\u001b[39;00m synset\u001b[38;5;241m.\u001b[39m_lemmas:\n\u001b[1;32m   1674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m synset\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m==\u001b[39m ADJ_SAT:\n\u001b[0;32m-> 1675\u001b[0m         head_lemma \u001b[38;5;241m=\u001b[39m \u001b[43msynset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilar_tos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_lemmas[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1676\u001b[0m         head_name \u001b[38;5;241m=\u001b[39m head_lemma\u001b[38;5;241m.\u001b[39m_name\n\u001b[1;32m   1677\u001b[0m         head_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%02d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m head_lemma\u001b[38;5;241m.\u001b[39m_lex_id\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:204\u001b[0m, in \u001b[0;36m_WordNetObject.similar_tos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilar_tos\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_related\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m&\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1102\u001b[0m, in \u001b[0;36mSynset._related\u001b[0;34m(self, relation_symbol, sort)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m   1101\u001b[0m pointer_tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pointers[relation_symbol]\n\u001b[0;32m-> 1102\u001b[0m r \u001b[38;5;241m=\u001b[39m [\u001b[43mget_synset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pos, offset \u001b[38;5;129;01min\u001b[39;00m pointer_tuples]\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort:\n\u001b[1;32m   1104\u001b[0m     r\u001b[38;5;241m.\u001b[39msort()\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1559\u001b[0m, in \u001b[0;36mWordNetCorpusReader.synset_from_pos_and_offset\u001b[0;34m(self, pos, offset)\u001b[0m\n\u001b[1;32m   1554\u001b[0m line_offset \u001b[38;5;241m=\u001b[39m data_file_line[:\u001b[38;5;241m8\u001b[39m]\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1556\u001b[0m     line_offset\u001b[38;5;241m.\u001b[39misalnum()\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m line_offset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(offset)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(offset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1558\u001b[0m ):\n\u001b[0;32m-> 1559\u001b[0m     synset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_synset_from_pos_and_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_file_line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1560\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m synset\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m==\u001b[39m offset\n\u001b[1;32m   1561\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_synset_offset_cache[pos][offset] \u001b[38;5;241m=\u001b[39m synset\n",
      "File \u001b[0;32m~/Documents/bloom-filters/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1587\u001b[0m, in \u001b[0;36mWordNetCorpusReader._synset_from_pos_and_line\u001b[0;34m(self, pos, data_file_line)\u001b[0m\n\u001b[1;32m   1585\u001b[0m columns_str, gloss \u001b[38;5;241m=\u001b[39m data_file_line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1586\u001b[0m definition \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m].*?[\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, gloss)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m-> 1587\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m([^\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]*)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m examples:\n\u001b[1;32m   1589\u001b[0m     synset\u001b[38;5;241m.\u001b[39m_examples\u001b[38;5;241m.\u001b[39mappend(example)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/__init__.py:217\u001b[0m, in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.corpus import wordnet\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
    "\n",
    "lemmatize = lambda word: nlp(str(word))[0].lemma_\n",
    "\n",
    "import json\n",
    "with open('data/wikipedia_20000_frequencies.json', 'r') as f:\n",
    "    frequencies = json.load(f)\n",
    "\n",
    "import pandas as pd\n",
    "for k, v in frequencies.items(): # applies new lemmatizer\n",
    "    frequencies[k] = pd.DataFrame({'word':v.keys(), 'frequency':v.values()}) \n",
    "    frequencies[k] = frequencies[k].loc[frequencies[k]['word'].map(lambda x: bool(wordnet.synsets(str(x))))]\n",
    "    frequencies[k]['lemmas'] = frequencies[k]['word'].map(lemmatize)\n",
    "    frequencies[k] = frequencies[k].groupby(frequencies[k]['lemmas']).aggregate({'frequency': 'sum'})\n",
    "    frequencies[k] = frequencies[k][pd.notnull(frequencies[k].index)].to_dict()['frequency']\n",
    "\n",
    "with open('data/wikipedia_20000_frequencies.json', 'w') as f:\n",
    "    json.dump(frequencies, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_wiki_frequencies = pd.read_csv('data/enwiki-2023-04-13.txt', header=None, sep=\" \", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_entries = en_wiki_frequencies.index.map(lambda x: bool(wordnet.synsets(str(x))))\n",
    "en_wiki_frequencies = en_wiki_frequencies.loc[valid_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_wiki_frequencies['lemmas'] = en_wiki_frequencies.index.map(lemmatize)\n",
    "en_wiki_frequencies = en_wiki_frequencies.groupby(en_wiki_frequencies['lemmas']).aggregate({1: 'sum'})\n",
    "\n",
    "en_wiki_frequencies = en_wiki_frequencies[pd.notnull(en_wiki_frequencies.index)].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_wiki_frequencies = en_wiki_frequencies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lemma_safe_enwiki_frequencies.json', 'w') as f:\n",
    "    json.dump(en_wiki_frequencies, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in frequencies.keys():\n",
    "    tf_idfs[word] = {}\n",
    "    for adjacent_word in frequencies[word].keys():\n",
    "        if frequencies[word][adjacent_word] < 5 or adjacent_word not in en_wiki_frequencies:\n",
    "            continue\n",
    "        tf_idfs[word][adjacent_word] = frequencies[word][adjacent_word] * 1.0 / en_wiki_frequencies[adjacent_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmh3\n",
    "\n",
    "def hash_digests(token, bits):\n",
    "    return [mmh3.hash(token, i) % bits for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tf_idfs.keys():\n",
    "    tf_idfs[key] = dict(sorted(tf_idfs[key].items(), key=lambda item: item[1], reverse=True))\n",
    "for key in tf_idfs.keys():\n",
    "    for word in tf_idfs[key].keys():\n",
    "        tf_idfs[key][word] = {\n",
    "            'tf-idf': tf_idfs[key][word],\n",
    "            'bloom_filter': list(hash_digests(word, 32))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes newlines in lists for readability\n",
    "import re\n",
    "def repl_func(match: re.Match):\n",
    "    return \" \".join(match.group().split())\n",
    "\n",
    "json_str = json.dumps(tf_idfs, indent=4)\n",
    "json_str = re.sub(r\"(?<=\\[)[^\\[\\]]+(?=])\", repl_func, json_str)\n",
    "\n",
    "with open('data/wikipedia_20000_tf-idf.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
